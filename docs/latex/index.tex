\hypertarget{index_overview}{}\section{Overview}\label{index_overview}
{\itshape libjanus} is a {\itshape C} A\+P\+I for the I\+A\+R\+P\+A Janus program consisting of two header files\+:

\begin{TabularC}{4}
\hline
\rowcolor{lightgray}{\bf Header }&{\bf Documentation }&{\bf Required }&{\bf Description  }\\\cline{1-4}
\hyperlink{iarpa__janus_8h_source}{iarpa\+\_\+janus.\+h} &\hyperlink{group__janus}{Janus} &{\bfseries Yes} &Mandatory interface for Phase 2 of the Janus program. \\\cline{1-4}
\hyperlink{iarpa__janus__io_8h_source}{iarpa\+\_\+janus\+\_\+io.\+h} &\hyperlink{group__janus__io}{Janus I/\+O} &No (Provided) &Media decoding and evaluation harness. \\\cline{1-4}
\end{TabularC}

\begin{DoxyItemize}
\item \href{https://github.com/Noblis/janice}{\tt {\bfseries Source Code}} \mbox{[}github.\+com\mbox{]}
\end{DoxyItemize}\hypertarget{index_about}{}\subsection{About}\label{index_about}
Intelligence analysts often rely on facial images to assist in establishing the identity of an individual, but too often, just examining the sheer volume of possibly relevant images and videos can be daunting. While biometric tools like automated face recognition could assist analysts in this task, current tools perform best on the well-\/posed, frontal facial photos taken for identification purposes. I\+A\+R\+P\+A’s Janus program aims to dramatically improve the current performance of face recognition tools by fusing the rich spatial, temporal, and contextual information available from the multiple views captured by today’s “media in the wild”. The program will move beyond largely two-\/dimensional image matching methods used currently into more model-\/based matching that fuses all views from whatever video and stills are available. Data volume now becomes an integral part of the solution instead of an oppressive burden.

The program is seeking to fund rigorous, high-\/quality research which uses innovative and promising approaches drawn from a variety of fields to develop novel representational models capable of encoding the shape, texture, and dynamics of a face. Instead of relying on a “single best frame approach,” these representations must address the challenges of Aging, Pose, Illumination, and Expression (A-\/\+P\+I\+E) by exploiting all available imagery. Technologies must support analysts working with partial information by addressing the uncertainties which arise when working with possibly incomplete, erroneous, and ambiguous data. The goal of the program is to test and validate techniques which have the potential to significantly improve the performance of biometric recognition in unconstrained imagery, to that end, the program will involve empirical testing of recognition performance across unconstrained videos, camera stills, and scanned photos exhibiting a broad range of real-\/world imaging conditions.

It is anticipated that successful teams will transcend conventional approaches to biometric recognition by drawing on the multidisciplinary expertise of researchers from the fields of pattern recognition and machine learning; computer vision and image processing; computer graphics and animation; mathematical statistics and modeling; and data visualization and analytics.\hypertarget{index_license}{}\subsection{License}\label{index_license}
The A\+P\+I is provided under a \href{LICENSE.txt}{\tt B\+S\+D-\/like license} and is {\itshape free for academic and commercial use}.\hypertarget{index_attribution}{}\subsection{Attribution}\label{index_attribution}
This research is based upon work supported by the Office of the Director of National Intelligence (O\+D\+N\+I), Intelligence Advanced Research Projects Activity (I\+A\+R\+P\+A), via the Army Research Laboratory. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of O\+D\+N\+I, I\+A\+R\+P\+A, or the U.\+S. Government. The U.\+S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. 